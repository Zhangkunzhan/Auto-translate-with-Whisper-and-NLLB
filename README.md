# Auto-translate with Whisper and NLLB

ä¸€ä¸ª **æœ¬åœ°éƒ¨ç½²çš„è¯­éŸ³ç¿»è¯‘é¡¹ç›®**ï¼ŒåŸºäº **Whisperï¼ˆASRï¼‰ + NLLBï¼ˆæœºå™¨ç¿»è¯‘ï¼‰**ï¼Œæ”¯æŒå®æ—¶éº¦å…‹é£è¾“å…¥å’ŒéŸ³é¢‘æ–‡ä»¶ç¿»è¯‘ï¼Œæ”¯æŒ CPU / GPUã€‚

---

## åŠŸèƒ½ç®€ä»‹

- ğŸ™ï¸ è¯­éŸ³è½¬æ–‡å­—ï¼ˆWhisper / faster-whisperï¼‰
- ğŸŒ å¤šè¯­è¨€ç¿»è¯‘ï¼ˆFacebook NLLB-200ï¼‰
- ğŸ§  å…¨ç¨‹æœ¬åœ°è¿è¡Œï¼Œæ— éœ€åœ¨çº¿ API
- âš¡ æ”¯æŒ GPU åŠ é€Ÿï¼ˆå¯é€‰ï¼‰

---

## é¡¹ç›®ç»“æ„

```text
Auto-translate-with-Whisper-and-NLLB/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ autotranslate.py      # å®æ—¶éŸ³é¢‘ç¿»è¯‘
â”‚   â”œâ”€â”€ mp3translate.py       # éŸ³é¢‘æ–‡ä»¶ç¿»è¯‘
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ README.md             # æ¨¡å‹ä¸‹è½½è¯´æ˜ï¼ˆæ¨¡å‹ä¸è¿›ä»“åº“ï¼‰
â”œâ”€â”€ requirements.txt          # Python ä¾èµ–ï¼ˆç²¾ç®€ç‰ˆï¼‰
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
ç¯å¢ƒè¦æ±‚
Python >= 3.9

æ¨èä½¿ç”¨ Conda æˆ– venv

ï¼ˆå¯é€‰ï¼‰NVIDIA GPU + CUDA

å®‰è£…ä¾èµ–ï¼ˆLibrariesï¼‰
1ï¸âƒ£ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
Conda
bash
å¤åˆ¶ä»£ç 
conda create -n translate python=3.10
conda activate translate
venv
bash
å¤åˆ¶ä»£ç 
python -m venv .venv
source .venv/bin/activate
2ï¸âƒ£ å®‰è£… Python ä¾èµ–
bash
å¤åˆ¶ä»£ç 
pip install -r requirements.txt
requirements.txt ç¤ºä¾‹
text
å¤åˆ¶ä»£ç 
torch
faster-whisper
transformers
ctranslate2
numpy
sounddevice
æ¨¡å‹ç®¡ç†ï¼ˆModelsï¼‰ã€é‡è¦ã€‘
âš ï¸ æ¨¡å‹ä½“ç§¯è¾ƒå¤§ï¼Œä¸ç›´æ¥æäº¤åˆ° GitHub

æœ¬é¡¹ç›®é‡‡ç”¨ ä»£ç ä¸æ¨¡å‹åˆ†ç¦» çš„æ–¹å¼ç®¡ç†æ¨¡å‹ã€‚

Whisper æ¨¡å‹ï¼ˆASRï¼‰
ä½¿ç”¨ faster-whisper

é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½

é»˜è®¤ä¸‹è½½ç›®å½•ï¼šmodels/

ç¤ºä¾‹ä»£ç ï¼š

python
å¤åˆ¶ä»£ç 
WhisperModel("small", download_root="models")
å¯é€‰æ¨¡å‹ï¼š

tiny

base

smallï¼ˆæ¨èï¼‰

medium

large-v3

NLLB ç¿»è¯‘æ¨¡å‹ï¼ˆMTï¼‰
æ¨èæ¨¡å‹ï¼š

facebook/nllb-200-distilled-600M

æ‰‹åŠ¨ä¸‹è½½ï¼ˆæ¨èï¼‰
ä½¿ç”¨ HuggingFace CLIï¼š

bash
å¤åˆ¶ä»£ç 
pip install huggingface-hub
hf download facebook/nllb-200-distilled-600M \
  --local-dir models/nllb \
  --local-dir-use-symlinks False
æˆ–ä½¿ç”¨ Python è„šæœ¬ï¼š

python
å¤åˆ¶ä»£ç 
from huggingface_hub import snapshot_download

snapshot_download(
    repo_id="facebook/nllb-200-distilled-600M",
    local_dir="models/nllb",
    local_dir_use_symlinks=False
)
æ¨¡å‹ç›®å½•ç»“æ„ç¤ºä¾‹
text
å¤åˆ¶ä»£ç 
models/
â”œâ”€â”€ whisper-small/
â””â”€â”€ nllb/
    â”œâ”€â”€ config.json
    â”œâ”€â”€ pytorch_model.bin
    â””â”€â”€ tokenizer.json
è¿è¡Œé¡¹ç›®
å®æ—¶éº¦å…‹é£ç¿»è¯‘
bash
å¤åˆ¶ä»£ç 
python src/autotranslate.py
ç¿»è¯‘éŸ³é¢‘æ–‡ä»¶
bash
å¤åˆ¶ä»£ç 
python src/mp3translate.py input.mp3
CPU / GPU è¯´æ˜
CPUï¼šæ— éœ€é¢å¤–é…ç½®ï¼Œé€Ÿåº¦è¾ƒæ…¢

GPUï¼š

å®‰è£… CUDA å¯¹åº”ç‰ˆæœ¬çš„ PyTorch

faster-whisper ä¼šè‡ªåŠ¨ä½¿ç”¨ GPU

æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨ï¼š

python
å¤åˆ¶ä»£ç 
import torch
print(torch.cuda.is_available())
.gitignore ç¤ºä¾‹
gitignore
å¤åˆ¶ä»£ç 
models/
*.bin
*.pt
__pycache__/
.venv/
å¸¸è§é—®é¢˜
Q: ä¸ºä»€ä¹ˆä¸æŠŠæ¨¡å‹ç›´æ¥æäº¤åˆ° GitHubï¼Ÿ
A: æ¨¡å‹ä½“ç§¯å¤§ï¼ŒGitHub æœ‰å¤§å°é™åˆ¶ï¼Œä¸åˆ©äºç»´æŠ¤ã€‚

Q: ç¬¬ä¸€æ¬¡è¿è¡Œå¾ˆæ…¢ï¼Ÿ
A: æ­£åœ¨ä¸‹è½½æ¨¡å‹ï¼Œå±äºæ­£å¸¸ç°è±¡ã€‚

License
MIT License

ä½œè€…
Kun / Zhangkunzhan
With the help of chatgpt and doubao
